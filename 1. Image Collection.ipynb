{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import opencv\n",
    "import cv2 \n",
    "\n",
    "# Import uuid\n",
    "import uuid\n",
    "\n",
    "# Import Operating System\n",
    "import os\n",
    "\n",
    "# Import time\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define Images to Collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['thumbsup', 'thumbsdown', 'thankyou', 'livelong']\n",
    "number_imgs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Setup Folders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nt\n"
     ]
    }
   ],
   "source": [
    "IMAGES_PATH = os.path.join('Tensorflow', 'workspace', 'images', 'collectedimages')\n",
    "print(os.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(IMAGES_PATH):\n",
    "    if os.name == 'posix':                  # for linux operation system\n",
    "        !mkdir -p {IMAGES_PATH}\n",
    "    if os.name == 'nt':                     # for windows operation system\n",
    "         !mkdir {IMAGES_PATH}\n",
    "for label in labels:\n",
    "    path = os.path.join(IMAGES_PATH, label)\n",
    "    if not os.path.exists(path):\n",
    "        !mkdir {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Capture Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting images for thumbsup\n",
      "Collecting image 0\n",
      "Collecting image 1\n",
      "Collecting image 2\n",
      "Collecting image 3\n",
      "Collecting image 4\n",
      "Collecting images for thumbsdown\n",
      "Collecting image 0\n",
      "Collecting image 1\n",
      "Collecting image 2\n",
      "Collecting image 3\n",
      "Collecting image 4\n",
      "Collecting images for thankyou\n",
      "Collecting image 0\n",
      "Collecting image 1\n",
      "Collecting image 2\n",
      "Collecting image 3\n",
      "Collecting image 4\n",
      "Collecting images for livelong\n",
      "Collecting image 0\n",
      "Collecting image 1\n",
      "Collecting image 2\n",
      "Collecting image 3\n",
      "Collecting image 4\n"
     ]
    }
   ],
   "source": [
    "for label in labels:\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    print('Collecting images for {}'.format(label))\n",
    "    time.sleep(5)\n",
    "    for imgnum in range(number_imgs):\n",
    "        print('Collecting image {}'.format(imgnum))\n",
    "        imgname = os.path.join(IMAGES_PATH,label,label+'.'+'{}.jpg'.format(str(uuid.uuid1())))    \n",
    "        while(1):\n",
    "            ret, frame = cap.read()\n",
    "            cv2.imshow('frame', frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "                break\n",
    "        cv2.imwrite(imgname, frame)        \n",
    "        time.sleep(2)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Image Labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyqt5 in g:\\tfodcourse-main\\venv\\lib\\site-packages (5.15.7)\n",
      "Collecting lxml\n",
      "  Downloading lxml-4.9.1-cp38-cp38-win_amd64.whl (3.6 MB)\n",
      "     ---------------------------------------- 3.6/3.6 MB 656.3 kB/s eta 0:00:00\n",
      "Requirement already satisfied: PyQt5-sip<13,>=12.11 in g:\\tfodcourse-main\\venv\\lib\\site-packages (from pyqt5) (12.11.0)\n",
      "Requirement already satisfied: PyQt5-Qt5>=5.15.0 in g:\\tfodcourse-main\\venv\\lib\\site-packages (from pyqt5) (5.15.2)\n",
      "Installing collected packages: lxml\n",
      "Successfully installed lxml-4.9.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "object-detection 0.1 requires apache-beam, which is not installed.\n",
      "object-detection 0.1 requires avro-python3, which is not installed.\n",
      "object-detection 0.1 requires contextlib2, which is not installed.\n",
      "object-detection 0.1 requires pycocotools, which is not installed.\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pyqt5 lxml  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELIMG_PATH = os.path.join('Tensorflow', 'labelimg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'Tensorflow\\labelimg'...\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(LABELIMG_PATH):\n",
    "    !mkdir {LABELIMG_PATH}\n",
    "    !git clone https://github.com/tzutalin/labelImg {LABELIMG_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name == 'posix':\n",
    "    !make qt5py3\n",
    "if os.name =='nt':\n",
    "    !cd {LABELIMG_PATH} && pyrcc5 -o libs/resources.py resources.qrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image:F:\\Design_Programs\\Season5_LABs\\5th_First_Semster_LABs\\AI_Labs\\OurProject\\Tensorflow\\workspace\\images\\collectedimages\\thankyou\\thankyou.1c2d7026-685a-11ed-a57f-78843cae7a38.jpg -> Annotation:F:/Design_Programs/Season5_LABs/5th_First_Semster_LABs/AI_Labs/OurProject/Tensorflow/workspace/images/collectedimages/thankyou\\thankyou.1c2d7026-685a-11ed-a57f-78843cae7a38.xml\n",
      "Image:F:\\Design_Programs\\Season5_LABs\\5th_First_Semster_LABs\\AI_Labs\\OurProject\\Tensorflow\\workspace\\images\\collectedimages\\thankyou\\thankyou.29de23fa-685a-11ed-b810-78843cae7a38.jpg -> Annotation:F:/Design_Programs/Season5_LABs/5th_First_Semster_LABs/AI_Labs/OurProject/Tensorflow/workspace/images/collectedimages/thankyou\\thankyou.29de23fa-685a-11ed-b810-78843cae7a38.xml\n",
      "Image:F:\\Design_Programs\\Season5_LABs\\5th_First_Semster_LABs\\AI_Labs\\OurProject\\Tensorflow\\workspace\\images\\collectedimages\\thankyou\\thankyou.38c34104-685a-11ed-8b4c-78843cae7a38.jpg -> Annotation:F:/Design_Programs/Season5_LABs/5th_First_Semster_LABs/AI_Labs/OurProject/Tensorflow/workspace/images/collectedimages/thankyou\\thankyou.38c34104-685a-11ed-8b4c-78843cae7a38.xml\n",
      "Image:F:\\Design_Programs\\Season5_LABs\\5th_First_Semster_LABs\\AI_Labs\\OurProject\\Tensorflow\\workspace\\images\\collectedimages\\thankyou\\thankyou.259ed03f-685a-11ed-82bf-78843cae7a38.jpg -> Annotation:F:/Design_Programs/Season5_LABs/5th_First_Semster_LABs/AI_Labs/OurProject/Tensorflow/workspace/images/collectedimages/thankyou\\thankyou.259ed03f-685a-11ed-82bf-78843cae7a38.xml\n",
      "Image:F:\\Design_Programs\\Season5_LABs\\5th_First_Semster_LABs\\AI_Labs\\OurProject\\Tensorflow\\workspace\\images\\collectedimages\\thankyou\\thankyou.310567f2-685a-11ed-bd07-78843cae7a38.jpg -> Annotation:F:/Design_Programs/Season5_LABs/5th_First_Semster_LABs/AI_Labs/OurProject/Tensorflow/workspace/images/collectedimages/thankyou\\thankyou.310567f2-685a-11ed-bd07-78843cae7a38.xml\n"
     ]
    }
   ],
   "source": [
    "!cd {LABELIMG_PATH} && python labelImg.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Move them into a Training and Testing Partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPTIONAL - 7. Compress them for Colab Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = os.path.join('Tensorflow', 'workspace', 'images', 'train')\n",
    "TEST_PATH = os.path.join('Tensorflow', 'workspace', 'images', 'test')\n",
    "ARCHIVE_PATH = os.path.join('Tensorflow', 'workspace', 'images', 'archive.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tar: : Couldn't visit directory: No such file or directory\n",
      "tar: : Couldn't visit directory: No such file or directory\n",
      "tar: Error exit delayed from previous errors.\n"
     ]
    }
   ],
   "source": [
    "!tar -czvf {ARCHIVE_PATH} {TRAIN_PATH} {TEST_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "75e22d2d68f6df9713f3bee177e1f7484eb45630ff7837661e427d1cd02ad056"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
